import os
import csv
import time
import requests
from bs4 import BeautifulSoup
import webbrowser

INPUT_FILE = "pubmed_articles.csv"
OUTPUT_DIR = "pdfs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Miroirs Sci-Hub connus
SCI_HUB_MIRRORS = [
    "https://sci-hub.se",
    "https://sci-hub.ru",
    "https://sci-hub.st",
    "https://sci-hub.hkvisa.net",
]

def try_scihub_url(scihub_url):
    print(f"  ‚îî‚îÄ Tentative d'acc√®s √† : {scihub_url}")
    try:
        response = requests.get(scihub_url, timeout=15)
        if response.status_code != 200:
            print(f"  ‚úò √âchec de chargement (status {response.status_code})")
            return False, None

        soup = BeautifulSoup(response.content, "html.parser")
        iframe = soup.find("iframe")
        if not iframe or not iframe.get("src"):
            print(f"  ‚úò Aucune iframe trouv√©e (pas de PDF visible)")
            return False, None

        pdf_url = iframe["src"]
        if pdf_url.startswith("//"):
            pdf_url = "https:" + pdf_url
        elif pdf_url.startswith("/"):
            parts = scihub_url.split("/")
            pdf_url = parts[0] + "//" + parts[2] + pdf_url

        print(f"  ‚úî Lien PDF trouv√© : {pdf_url}")
        return True, pdf_url
    except Exception as e:
        print(f"  ‚úò Erreur lors de l'acc√®s √† {scihub_url} ‚Üí {e}")
        return False, None

def try_all_scihub_mirrors(doi):
    print(f"üîç Recherche du PDF pour DOI: {doi}")
    for mirror in SCI_HUB_MIRRORS:
        scihub_url = f"{mirror}/{doi}"
        success, pdf_url = try_scihub_url(scihub_url)
        if success:
            print(f"‚úÖ PDF localis√© via {mirror}")
            return pdf_url
    print(f"‚ùå Aucun miroir Sci-Hub n'a permis d'acc√©der au PDF.")
    return None

def main():
    print("=== üì• Lancement du t√©l√©chargement des PDF PubMed ===\n")
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        total = 0
        downloaded = 0
        for row in reader:
            total += 1
            pmid = row.get("PMID")
            doi = row.get("DOI")
            title = row.get("Title", "").strip()[:100]
            if not doi:
                print(f"[{pmid}] ‚ùå Aucun DOI ‚Äî article ignor√©")
                continue

            filename = f"{pmid}.pdf"
            output_path = os.path.join(OUTPUT_DIR, filename)

            print(f"\n=== ‚ñ∂Ô∏è Traitement de PMID {pmid} ===")
            print(f"    Titre : {title}")
            print(f"    DOI   : {doi}")

            if os.path.exists(output_path):
                print(f"    üü° D√©j√† t√©l√©charg√© : {filename}")
                continue

            print(f"    üì° Tentative de t√©l√©chargement du PDF...")
            pdf_url = try_all_scihub_mirrors(doi)

            if pdf_url:
                try:
                    print(f"    ‚¨áÔ∏è T√©l√©chargement du fichier PDF...")
                    pdf_response = requests.get(pdf_url, stream=True, timeout=20)
                    if pdf_response.status_code == 200:
                        with open(output_path, "wb") as f_out:
                            for chunk in pdf_response.iter_content(1024):
                                f_out.write(chunk)
                        print(f"    ‚úÖ PDF enregistr√© : {output_path}")
                        downloaded += 1
                    else:
                        print(f"    ‚ùå PDF non t√©l√©chargeable (status {pdf_response.status_code})")
                except Exception as e:
                    print(f"    ‚ùå Erreur pendant le t√©l√©chargement : {e}")
            else:
                fallback_url = f"https://sci-hub.se/{doi}"
                print(f"    üö™ Ouverture dans le navigateur : {fallback_url}")
                webbrowser.open(fallback_url)

            time.sleep(1.5)

    print("\n=== ‚úÖ Termin√© ===")
    print(f"Articles trait√©s : {total}")
    print(f"PDF t√©l√©charg√©s  : {downloaded}")
    print(f"PDF manquants    : {total - downloaded}")

if __name__ == "__main__":
    main()
